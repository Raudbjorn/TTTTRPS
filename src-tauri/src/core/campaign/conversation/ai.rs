//! Conversation AI Implementation
//!
//! Phase 5 of the Campaign Generation Overhaul.
//!
//! This module provides utility types and constants for AI-assisted conversation.
//! The actual LLM integration is handled in the Tauri commands module to avoid
//! complex ownership patterns with the async RwLock.

use serde::{Deserialize, Serialize};

use crate::database::{ConversationPurpose, Suggestion, SuggestionStatus};

use super::types::Citation;

// ============================================================================
// Response Types
// ============================================================================

/// Generated response from the AI.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct GeneratedResponse {
    /// The response content (with suggestion/citation blocks removed)
    pub content: String,
    /// Parsed suggestions from the response
    pub suggestions: Vec<Suggestion>,
    /// Parsed citations from the response
    pub citations: Vec<Citation>,
    /// The model used for generation
    pub model: String,
    /// Input tokens used (i64 to avoid truncation on large counts)
    pub tokens_in: i64,
    /// Output tokens generated (i64 to avoid truncation on large counts)
    pub tokens_out: i64,
}

/// A clarifying question generated by the AI.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ClarifyingQuestion {
    /// The question to ask
    pub question: String,
    /// The field this question relates to
    pub field: String,
    /// Whether this information is required or optional
    pub importance: String,
}

// ============================================================================
// System Prompts
// ============================================================================

/// Default system prompt for campaign creation
pub const CAMPAIGN_CREATION_SYSTEM_PROMPT: &str = r#"You are a helpful TTRPG assistant specializing in campaign creation.
You help Game Masters develop rich, engaging campaigns with coherent themes and interesting plot hooks.

When making suggestions, format them as JSON blocks that can be parsed:
```suggestion
{
  "field": "name",
  "value": "The Shattered Crown",
  "rationale": "This name evokes mystery and conflict, fitting your dark fantasy theme."
}
```

When citing source material, include references:
```citation
{
  "source_name": "Player's Handbook",
  "location": "p. 123",
  "excerpt": "The relevant text..."
}
```

Be concise but thorough. Ask clarifying questions when the user's intent is unclear.
Always maintain the established tone and themes of the campaign."#;

/// System prompt for session planning
pub const SESSION_PLANNING_SYSTEM_PROMPT: &str = r#"You are a helpful TTRPG assistant specializing in session planning.
You help Game Masters prepare engaging sessions with balanced pacing and memorable encounters.

Focus on:
- Scene-by-scene breakdowns
- NPC motivations and dialogue hooks
- Encounter balance suggestions
- Backup plans for player divergence

Use the same suggestion and citation formats as campaign creation when applicable."#;

/// System prompt for NPC generation
pub const NPC_GENERATION_SYSTEM_PROMPT: &str = r#"You are a helpful TTRPG assistant specializing in NPC creation.
You help create memorable, three-dimensional characters with clear motivations and flaws.

Consider:
- Personality traits and mannerisms
- Backstory and secrets
- Relationships with other NPCs
- Quest hooks they could provide
- Voice and speech patterns

Format suggestions for NPC attributes using the standard suggestion blocks."#;

/// System prompt for world building
pub const WORLD_BUILDING_SYSTEM_PROMPT: &str = r#"You are a helpful TTRPG assistant specializing in world building.
You help create rich, consistent settings with interesting history and cultures.

Focus on:
- Geographic features and locations
- Political structures and factions
- Cultural traditions and conflicts
- Historical events and their consequences
- Mysteries and secrets of the world

Ground your suggestions in established lore when possible, citing sources."#;

/// Get the appropriate system prompt for the conversation purpose.
pub fn get_system_prompt(purpose: ConversationPurpose) -> &'static str {
    match purpose {
        ConversationPurpose::CampaignCreation => CAMPAIGN_CREATION_SYSTEM_PROMPT,
        ConversationPurpose::SessionPlanning => SESSION_PLANNING_SYSTEM_PROMPT,
        ConversationPurpose::NpcGeneration => NPC_GENERATION_SYSTEM_PROMPT,
        ConversationPurpose::WorldBuilding => WORLD_BUILDING_SYSTEM_PROMPT,
        ConversationPurpose::CharacterBackground => NPC_GENERATION_SYSTEM_PROMPT, // Similar to NPC
        ConversationPurpose::General => CAMPAIGN_CREATION_SYSTEM_PROMPT, // Default to campaign
    }
}

// ============================================================================
// Response Parsing Utilities
// ============================================================================

/// Parse the LLM response for suggestions and citations.
///
/// Returns the cleaned content along with parsed suggestions and citations.
pub fn parse_response(response: &str) -> (String, Vec<Suggestion>, Vec<Citation>) {
    let mut suggestions = Vec::new();
    let mut citations = Vec::new();
    let mut content = response.to_string();

    // Parse suggestion blocks
    if let Ok(suggestion_regex) = regex::Regex::new(r"```suggestion\s*\n([\s\S]*?)\n```") {
        for cap in suggestion_regex.captures_iter(response) {
            if let Some(json_str) = cap.get(1) {
                if let Some(suggestion) = parse_suggestion(json_str.as_str()) {
                    suggestions.push(suggestion);
                }
            }
        }
        // Remove suggestion blocks from content
        content = suggestion_regex.replace_all(&content, "").to_string();
    }

    // Parse citation blocks
    if let Ok(citation_regex) = regex::Regex::new(r"```citation\s*\n([\s\S]*?)\n```") {
        for cap in citation_regex.captures_iter(response) {
            if let Some(json_str) = cap.get(1) {
                if let Some(citation) = parse_citation(json_str.as_str()) {
                    citations.push(citation);
                }
            }
        }
        // Remove citation blocks from content
        content = citation_regex.replace_all(&content, "").to_string();
    }

    // Clean up extra whitespace
    content = content.trim().to_string();

    (content, suggestions, citations)
}

/// Parse a single suggestion from JSON.
fn parse_suggestion(json_str: &str) -> Option<Suggestion> {
    #[derive(Deserialize)]
    struct RawSuggestion {
        field: String,
        value: serde_json::Value,
        rationale: String,
    }

    match serde_json::from_str::<RawSuggestion>(json_str) {
        Ok(raw) => Some(Suggestion {
            id: uuid::Uuid::new_v4().to_string(),
            field: raw.field,
            value: raw.value,
            rationale: raw.rationale,
            status: SuggestionStatus::Pending,
        }),
        Err(e) => {
            tracing::warn!(error = %e, json = json_str, "Failed to parse suggestion");
            None
        }
    }
}

/// Parse a single citation from JSON.
fn parse_citation(json_str: &str) -> Option<Citation> {
    #[derive(Deserialize)]
    struct RawCitation {
        source_name: String,
        location: Option<String>,
        excerpt: Option<String>,
    }

    match serde_json::from_str::<RawCitation>(json_str) {
        Ok(raw) => {
            let mut citation =
                Citation::new(uuid::Uuid::new_v4().to_string(), raw.source_name, 0.8);
            if let Some(loc) = raw.location {
                citation = citation.with_location(loc);
            }
            if let Some(exc) = raw.excerpt {
                citation = citation.with_excerpt(exc);
            }
            Some(citation)
        }
        Err(e) => {
            tracing::warn!(error = %e, json = json_str, "Failed to parse citation");
            None
        }
    }
}

/// Parse clarifying questions from the response.
pub fn parse_clarifying_questions(response: &str) -> Vec<ClarifyingQuestion> {
    // Try to find a JSON array in the response
    if let Ok(json_regex) = regex::Regex::new(r"\[[\s\S]*\]") {
        if let Some(json_match) = json_regex.find(response) {
            if let Ok(questions) =
                serde_json::from_str::<Vec<ClarifyingQuestion>>(json_match.as_str())
            {
                return questions;
            }
        }
    }

    // If parsing fails, return empty
    tracing::warn!("Failed to parse clarifying questions from response");
    Vec::new()
}

// ============================================================================
// Tests
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parse_suggestion() {
        let json = r#"{
            "field": "name",
            "value": "The Dark Crusade",
            "rationale": "Fits the dark fantasy theme"
        }"#;

        let suggestion = parse_suggestion(json).unwrap();
        assert_eq!(suggestion.field, "name");
        assert_eq!(suggestion.value, serde_json::json!("The Dark Crusade"));
        assert_eq!(suggestion.status, SuggestionStatus::Pending);
    }

    #[test]
    fn test_parse_citation() {
        let json = r#"{
            "source_name": "Player's Handbook",
            "location": "p. 123",
            "excerpt": "The fighter class..."
        }"#;

        let citation = parse_citation(json).unwrap();
        assert_eq!(citation.source_name, "Player's Handbook");
        assert_eq!(citation.location, Some("p. 123".to_string()));
    }

    #[test]
    fn test_parse_response_with_suggestions() {
        let response = r#"Here's a suggestion for your campaign name:

```suggestion
{
    "field": "name",
    "value": "The Shattered Crown",
    "rationale": "Evokes mystery and conflict"
}
```

Let me know if you'd like more options!"#;

        let (content, suggestions, citations) = parse_response(response);

        assert!(!content.contains("```suggestion"));
        assert_eq!(suggestions.len(), 1);
        assert_eq!(suggestions[0].field, "name");
        assert!(citations.is_empty());
    }

    #[test]
    fn test_parse_response_with_citations() {
        let response = r#"According to the rules:

```citation
{
    "source_name": "DMG",
    "location": "p. 45",
    "excerpt": "Building encounters..."
}
```

This helps with balancing."#;

        let (content, suggestions, citations) = parse_response(response);

        assert!(!content.contains("```citation"));
        assert!(suggestions.is_empty());
        assert_eq!(citations.len(), 1);
        assert_eq!(citations[0].source_name, "DMG");
    }

    #[test]
    fn test_get_system_prompt() {
        let prompt = get_system_prompt(ConversationPurpose::CampaignCreation);
        assert!(prompt.contains("campaign creation"));

        let prompt = get_system_prompt(ConversationPurpose::SessionPlanning);
        assert!(prompt.contains("session planning"));

        let prompt = get_system_prompt(ConversationPurpose::NpcGeneration);
        assert!(prompt.contains("NPC creation"));
    }

    #[test]
    fn test_parse_clarifying_questions() {
        let response = r#"Based on the context, here are some questions:
[
    {"question": "What level will the party be?", "field": "level", "importance": "required"},
    {"question": "Any themes to avoid?", "field": "avoid", "importance": "optional"}
]"#;

        let questions = parse_clarifying_questions(response);
        assert_eq!(questions.len(), 2);
        assert_eq!(questions[0].field, "level");
        assert_eq!(questions[1].importance, "optional");
    }

    #[test]
    fn test_generated_response_serialization() {
        let response = GeneratedResponse {
            content: "Test response".to_string(),
            suggestions: vec![],
            citations: vec![],
            model: "test-model".to_string(),
            tokens_in: 100,
            tokens_out: 50,
        };

        let json = serde_json::to_string(&response).unwrap();
        assert!(json.contains("Test response"));
        assert!(json.contains("test-model"));
    }
}
