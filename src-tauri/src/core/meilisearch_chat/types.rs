//! Data transfer objects and types for Meilisearch Chat
//!
//! Contains message types, streaming response types, tool call definitions,
//! and error response structures.

use serde::{Deserialize, Serialize};

// ============================================================================
// Meilisearch Chat Tools
// ============================================================================

/// Tool definitions for Meilisearch chat requests.
/// These tools enable RAG functionality and conversation context management.
pub fn get_meilisearch_chat_tools() -> Vec<serde_json::Value> {
    vec![
        // Progress reporting tool
        serde_json::json!({
            "type": "function",
            "function": {
                "name": "_meiliSearchProgress",
                "description": "Provides information about the current Meilisearch search operation",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "call_id": {
                            "type": "string",
                            "description": "The call ID to track the sources of the search"
                        },
                        "function_name": {
                            "type": "string",
                            "description": "The name of the function we are executing"
                        },
                        "function_parameters": {
                            "type": "string",
                            "description": "The parameters of the function we are executing, encoded in JSON"
                        }
                    },
                    "required": ["call_id", "function_name", "function_parameters"],
                    "additionalProperties": false
                },
                "strict": true
            }
        }),
        // Conversation context management tool
        serde_json::json!({
            "type": "function",
            "function": {
                "name": "_meiliAppendConversationMessage",
                "description": "Append a new message to the conversation based on what happened internally. Used to maintain conversation context for stateless chat.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "role": {
                            "type": "string",
                            "description": "The role of the message author: 'assistant' or 'tool'"
                        },
                        "content": {
                            "type": ["string", "null"],
                            "description": "The contents of the message. Required unless tool_calls is specified."
                        },
                        "tool_calls": {
                            "type": ["array", "null"],
                            "description": "The tool calls generated by the model",
                            "items": {
                                "type": "object",
                                "properties": {
                                    "function": {
                                        "type": "object",
                                        "description": "The function that the model called",
                                        "properties": {
                                            "name": {
                                                "type": "string",
                                                "description": "The name of the function to call"
                                            },
                                            "arguments": {
                                                "type": "string",
                                                "description": "The arguments to call the function with, as JSON"
                                            }
                                        }
                                    },
                                    "id": {
                                        "type": "string",
                                        "description": "The ID of the tool call"
                                    },
                                    "type": {
                                        "type": "string",
                                        "description": "The type of the tool (currently only 'function')"
                                    }
                                }
                            }
                        },
                        "tool_call_id": {
                            "type": ["string", "null"],
                            "description": "Tool call ID that this message is responding to"
                        }
                    },
                    "required": ["role", "content", "tool_calls", "tool_call_id"],
                    "additionalProperties": false
                },
                "strict": true
            }
        }),
        // Source documents tool
        serde_json::json!({
            "type": "function",
            "function": {
                "name": "_meiliSearchSources",
                "description": "Provides source documents from the search results",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "call_id": {
                            "type": "string",
                            "description": "The call ID to track the original search associated to those sources"
                        },
                        "documents": {
                            "type": "object",
                            "description": "The documents associated with the search. Only displayed attributes are returned."
                        }
                    },
                    "required": ["call_id", "documents"],
                    "additionalProperties": false
                },
                "strict": true
            }
        })
    ]
}

// ============================================================================
// Tool Call Types for Conversation Context
// ============================================================================

/// Arguments for _meiliAppendConversationMessage tool call
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AppendConversationMessageArgs {
    /// Message role: "assistant" or "tool"
    pub role: String,
    /// Message content (for tool results, may be null for assistant tool_calls)
    pub content: Option<String>,
    /// Tool calls made by the assistant
    pub tool_calls: Option<Vec<ToolCallInfo>>,
    /// Tool call ID this message responds to
    pub tool_call_id: Option<String>,
}

/// Tool call information
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ToolCallInfo {
    /// Unique ID for this tool call
    pub id: String,
    /// Type of tool (always "function" currently)
    #[serde(rename = "type")]
    pub call_type: String,
    /// Function details
    pub function: ToolCallFunction,
}

/// Function details within a tool call
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ToolCallFunction {
    /// Function name
    pub name: String,
    /// Function arguments as JSON string
    pub arguments: String,
}

/// Arguments for _meiliSearchProgress tool call
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SearchProgressArgs {
    /// Call ID to track this search
    pub call_id: String,
    /// Function being executed
    pub function_name: String,
    /// Function parameters as JSON string
    pub function_parameters: String,
}

/// Arguments for _meiliSearchSources tool call
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SearchSourcesArgs {
    /// Call ID linking to the original search
    pub call_id: String,
    /// Source documents
    pub documents: serde_json::Value,
}

/// Parsed tool call from stream
#[derive(Debug, Clone)]
pub enum ParsedToolCall {
    /// Conversation message to append
    AppendMessage(AppendConversationMessageArgs),
    /// Search progress update
    SearchProgress(SearchProgressArgs),
    /// Search sources/documents
    SearchSources(SearchSourcesArgs),
    /// Unknown tool call
    Unknown { name: String, arguments: String },
}

impl ParsedToolCall {
    /// Parse a tool call from name and arguments JSON
    pub fn parse(name: &str, arguments: &str) -> Option<Self> {
        match name {
            "_meiliAppendConversationMessage" => {
                serde_json::from_str::<AppendConversationMessageArgs>(arguments)
                    .ok()
                    .map(ParsedToolCall::AppendMessage)
            }
            "_meiliSearchProgress" => {
                serde_json::from_str::<SearchProgressArgs>(arguments)
                    .ok()
                    .map(ParsedToolCall::SearchProgress)
            }
            "_meiliSearchSources" => {
                serde_json::from_str::<SearchSourcesArgs>(arguments)
                    .ok()
                    .map(ParsedToolCall::SearchSources)
            }
            _ => Some(ParsedToolCall::Unknown {
                name: name.to_string(),
                arguments: arguments.to_string(),
            }),
        }
    }
}

// ============================================================================
// Chat Message Types (OpenAI Compatible)
// ============================================================================

/// A chat message in the conversation
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatMessage {
    pub role: String,
    pub content: String,
}

impl ChatMessage {
    pub fn user(content: &str) -> Self {
        Self {
            role: "user".to_string(),
            content: content.to_string(),
        }
    }

    pub fn assistant(content: &str) -> Self {
        Self {
            role: "assistant".to_string(),
            content: content.to_string(),
        }
    }

    pub fn system(content: &str) -> Self {
        Self {
            role: "system".to_string(),
            content: content.to_string(),
        }
    }
}

/// Chat completion request
#[derive(Debug, Clone, Serialize)]
pub struct ChatCompletionRequest {
    pub model: String,
    pub messages: Vec<ChatMessage>,
    pub stream: bool,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub temperature: Option<f32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub max_tokens: Option<u32>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub tools: Option<Vec<serde_json::Value>>,
}

/// Streaming response delta
#[derive(Debug, Clone, Deserialize)]
pub struct StreamDelta {
    #[serde(default)]
    pub content: Option<String>,
    #[serde(default)]
    pub role: Option<String>,
    #[serde(default)]
    pub tool_calls: Option<serde_json::Value>,
}

/// Streaming response choice
#[derive(Debug, Clone, Deserialize)]
pub struct StreamChoice {
    pub delta: StreamDelta,
    #[serde(default)]
    pub index: u32,
    #[serde(default)]
    pub finish_reason: Option<String>,
}

#[derive(Debug, Clone, Deserialize)]
pub struct StreamChunk {
    pub id: String,
    pub choices: Vec<StreamChoice>,
    #[serde(default)]
    pub model: Option<String>,
}

/// Error response from Meilisearch
#[derive(Debug, Clone, Deserialize)]
pub struct MeilisearchErrorResponse {
    pub error: MeilisearchErrorDetail,
    #[serde(rename = "type")]
    pub error_type: String,
}

#[derive(Debug, Clone, Deserialize)]
pub struct MeilisearchErrorDetail {
    pub message: String,
    #[serde(rename = "type")]
    pub error_type: String,
    pub code: Option<String>,
}

// ============================================================================
// Provider Information
// ============================================================================

/// Information about available chat providers
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ChatProviderInfo {
    pub id: &'static str,
    pub name: &'static str,
    pub description: &'static str,
    pub requires_api_key: bool,
    pub is_native: bool,
}

/// Get information about all available chat providers
pub fn list_chat_providers() -> Vec<ChatProviderInfo> {
    vec![
        ChatProviderInfo {
            id: "openai",
            name: "OpenAI",
            description: "GPT-4o, GPT-4, GPT-3.5 models",
            requires_api_key: true,
            is_native: true,
        },
        ChatProviderInfo {
            id: "claude",
            name: "Anthropic Claude",
            description: "Claude 3.5 Sonnet, Claude 3 Opus/Haiku",
            requires_api_key: true,
            is_native: false,
        },
        ChatProviderInfo {
            id: "mistral",
            name: "Mistral AI",
            description: "Mistral Large, Codestral, Mixtral",
            requires_api_key: true,
            is_native: true,
        },
        ChatProviderInfo {
            id: "ollama",
            name: "Ollama (Local)",
            description: "Run open models locally",
            requires_api_key: false,
            is_native: false,
        },
        ChatProviderInfo {
            id: "gemini",
            name: "Google Gemini",
            description: "Gemini Pro, Gemini Ultra",
            requires_api_key: true,
            is_native: false,
        },
        ChatProviderInfo {
            id: "openrouter",
            name: "OpenRouter",
            description: "Access many models via single API",
            requires_api_key: true,
            is_native: false,
        },
        ChatProviderInfo {
            id: "azure",
            name: "Azure OpenAI",
            description: "Azure-hosted OpenAI models",
            requires_api_key: true,
            is_native: true,
        },
        ChatProviderInfo {
            id: "groq",
            name: "Groq",
            description: "Fast inference with Llama, Mixtral",
            requires_api_key: true,
            is_native: false,
        },
        ChatProviderInfo {
            id: "together",
            name: "Together.ai",
            description: "Open models at scale",
            requires_api_key: true,
            is_native: false,
        },
        ChatProviderInfo {
            id: "cohere",
            name: "Cohere",
            description: "Command R+, Command models",
            requires_api_key: true,
            is_native: false,
        },
        ChatProviderInfo {
            id: "deepseek",
            name: "DeepSeek",
            description: "DeepSeek Coder, DeepSeek Chat",
            requires_api_key: true,
            is_native: false,
        },
        ChatProviderInfo {
            id: "grok",
            name: "Grok (xAI)",
            description: "Grok models from xAI",
            requires_api_key: true,
            is_native: true,  // OpenAI-compatible, no proxy needed
        },
    ]
}
